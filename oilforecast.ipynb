{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc63d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import ARIMA\n",
    "from arch import arch_model\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42b630dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion complete.\n",
      "Raw Data Head:\n",
      "            brent_price  wti_price        dxy  10y_yield        vix  \\\n",
      "Date                                                                  \n",
      "2007-07-30    75.739998  76.830002  80.849998      4.804  20.870001   \n",
      "2007-07-31    77.050003  78.209999  80.769997      4.771  23.520000   \n",
      "2007-08-01    75.349998  76.529999  80.870003      4.759  23.670000   \n",
      "2007-08-02    75.760002  76.860001  80.709999      4.753  21.219999   \n",
      "2007-08-03    74.750000  75.480003  80.180000      4.700  25.160000   \n",
      "\n",
      "            eia_inventories         cpi  industrial_production  \n",
      "Date                                                            \n",
      "2007-07-30              NaN         NaN                    NaN  \n",
      "2007-07-31              NaN  250.750811             100.132497  \n",
      "2007-08-01       502.074518         NaN                    NaN  \n",
      "2007-08-02              NaN         NaN                    NaN  \n",
      "2007-08-03              NaN         NaN                    NaN  \n"
     ]
    }
   ],
   "source": [
    "def ingest_data():\n",
    "    \"\"\"\n",
    "    Ingests raw time series data. Downloads daily data from Yahoo Finance and\n",
    "    simulates realistic weekly and monthly macroeconomic data.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "\n",
    "# Here we have the tickers from yfinance, maybe switch soon to a more reliable source.\n",
    "    tickers = {\n",
    "        'CL=F': 'wti_price',   # WTI Crude Oil Futures\n",
    "        'BZ=F': 'brent_price', # Brent Crude Oil Futures\n",
    "        'DX-Y.NYB': 'dxy',     # US Dollar Index\n",
    "        '^TNX': '10y_yield',   # 10-Year Treasury Yield\n",
    "        '^VIX': 'vix'          # CBOE Volatility Index\n",
    "    }\n",
    "\n",
    "\n",
    "    end=datetime.now().strftime('%Y-%m-%d')\n",
    "    # From 2005 to today\n",
    "    data = yf.download(list(tickers.keys()), start='2007-07-30', end=end, progress=False) # just for the bar\n",
    "    # We're only working with the price at the end of the day, so this will be measured on the scale of days.\n",
    "    data = data['Close'] # The price is already adjusted for splits and dividends\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    data = data.rename(columns=tickers)\n",
    "\n",
    "\n",
    "    # We can't have any missing values, so we'll forward fill them.\n",
    "    data = data.ffill().dropna() # Forward fill to handle non-trading days\n",
    "\n",
    "    # --- Simulate Weekly Data (EIA Inventories) ---\n",
    "    weekly_dates = pd.date_range(start=data.index.min(), end=data.index.max(), freq='W-WED') # We're using the end of the week as the measurement point.\n",
    "\n",
    "    # Ill have some random data here, but in reality this will be the EIA Inventories data, this will just trend up.\n",
    "    eia_inventories = pd.Series(\n",
    "        500 + (np.random.randn(len(weekly_dates)) * 10).cumsum(),\n",
    "        index=weekly_dates, name='eia_inventories'\n",
    "    )\n",
    "\n",
    "    # --- Simulate Monthly Data (CPI, Industrial Production) ---\n",
    "    monthly_dates = pd.date_range(start=data.index.min(), end=data.index.max(), freq='M')\n",
    "    cpi = pd.Series(\n",
    "        250 + (np.random.randn(len(monthly_dates)) * 0.5).cumsum(),\n",
    "        index=monthly_dates, name='cpi'\n",
    "    ) # We use 0.5 here because it represents inflation in a way, which is less volatile than the other data.\n",
    "\n",
    "\n",
    "    industrial_production = pd.Series(\n",
    "        100 + (np.random.randn(len(monthly_dates)) * 0.2).cumsum(),\n",
    "        index=monthly_dates, name='industrial_production'\n",
    "    ) # Very stable data, so we use 0.2.\n",
    "\n",
    "    # Merge all datasets into a single daily-frequency DataFrame\n",
    "    df = data.copy()\n",
    "    df = df.merge(eia_inventories, how='left', left_index=True, right_index=True)\n",
    "    df = df.merge(cpi, how='left', left_index=True, right_index=True)\n",
    "    df = df.merge(industrial_production, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # --- Data Catalog ---\n",
    "    metadata = {\n",
    "        'wti_price': {'frequency': 'daily', 'source': 'Yahoo Finance', 'publication_lag': '0D'},\n",
    "        'brent_price': {'frequency': 'daily', 'source': 'Yahoo Finance', 'publication_lag': '0D'},\n",
    "        'dxy': {'frequency': 'daily', 'source': 'Yahoo Finance', 'publication_lag': '0D'},\n",
    "        '10y_yield': {'frequency': 'daily', 'source': 'Yahoo Finance', 'publication_lag': '0D'},\n",
    "        'vix': {'frequency': 'daily', 'source': 'Yahoo Finance', 'publication_lag': '0D'},\n",
    "        'eia_inventories': {'frequency': 'weekly', 'source': 'Simulated', 'publication_lag': '5B'},\n",
    "        'cpi': {'frequency': 'monthly', 'source': 'Simulated', 'publication_lag': '10B'},\n",
    "        'industrial_production': {'frequency': 'monthly', 'source': 'Simulated', 'publication_lag': '12B'},\n",
    "    }\n",
    "\n",
    "    print(\"Data ingestion complete.\")\n",
    "    return df, metadata\n",
    "\n",
    "# Execute data ingestion\n",
    "raw_data, metadata = ingest_data()\n",
    "print(\"Raw Data Head:\")\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5021ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Free Historical Weather Data Integration\n",
    "# Install required packages for NOAA weather data\n",
    "%pip install requests --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc86d62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-Meteo setup ready\n"
     ]
    }
   ],
   "source": [
    "# Open-Meteo setup: city coordinates and fetch helper\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "city_coords = {\n",
    "    # US oil hubs and major cities\n",
    "    'Houston': (29.7604, -95.3698),\n",
    "    'Dallas': (32.7767, -96.7970),\n",
    "    'Denver': (39.7392, -104.9903),\n",
    "    'New York': (40.7128, -74.0060),\n",
    "    'Los Angeles': (34.0522, -118.2437),\n",
    "    'Chicago': (41.8781, -87.6298),\n",
    "    'London': (51.5074, -0.1278),\n",
    "    'Tokyo': (35.6762, 139.6503),\n",
    "}\n",
    "\n",
    "\n",
    "def fetch_weather_data(city_name, lat, lon, start_date, end_date, timezone=\"UTC\"):\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": [\n",
    "            \"temperature_2m_mean\",\n",
    "            \"precipitation_sum\",\n",
    "            \"wind_speed_10m_max\"\n",
    "        ],\n",
    "        \"timezone\": timezone\n",
    "    }\n",
    "    resp = requests.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    if \"daily\" not in data:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(data[\"daily\"])  # columns: time, temperature_2m_mean, precipitation_sum, wind_speed_10m_max\n",
    "    df[\"city\"] = city_name\n",
    "    return df\n",
    "\n",
    "print(\"Open-Meteo setup ready\")\n",
    "\n",
    "# Chunked fetch to avoid long single requests\n",
    "from datetime import date as _date\n",
    "from dateutil.relativedelta import relativedelta as _relativedelta\n",
    "import time as _time\n",
    "\n",
    "def _iter_date_chunks(start_date: str, end_date: str, chunk_days: int = 365):\n",
    "    start = pd.to_datetime(start_date).date()\n",
    "    end = pd.to_datetime(end_date).date()\n",
    "    cur = start\n",
    "    delta = pd.Timedelta(days=chunk_days)\n",
    "    while cur <= end:\n",
    "        nxt = min(pd.to_datetime(cur) + delta, pd.to_datetime(end))\n",
    "        yield cur.strftime('%Y-%m-%d'), nxt.strftime('%Y-%m-%d')\n",
    "        # advance by one day beyond nxt to avoid overlap\n",
    "        cur = (pd.to_datetime(nxt) + pd.Timedelta(days=1)).date()\n",
    "\n",
    "def fetch_city_weather_batched(city_name, lat, lon, start_date, end_date, timezone=\"UTC\", chunk_days=365, sleep_sec=0.2):\n",
    "    frames = []\n",
    "    for s, e in _iter_date_chunks(start_date, end_date, chunk_days):\n",
    "        df_part = fetch_weather_data(city_name, lat, lon, s, e, timezone=timezone)\n",
    "        if not df_part.empty:\n",
    "            frames.append(df_part)\n",
    "        _time.sleep(sleep_sec)\n",
    "    if frames:\n",
    "        return pd.concat(frames, ignore_index=True)\n",
    "    return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae30da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Getting weather data for major US cities (last 30 days)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Open-Meteo: fetch weather for analysis\n",
    "def get_weather_data_for_analysis(start_date, end_date, cities=None, usa_only=False, chunk_days=365, sleep_sec=0.2):\n",
    "    \"\"\"Fetch Open-Meteo daily weather for given cities and date range with chunking.\"\"\"\n",
    "    if usa_only or not cities:\n",
    "        target_cities = ['Houston', 'Dallas', 'Denver', 'New York', 'Los Angeles', 'Chicago']\n",
    "    else:\n",
    "        target_cities = [c for c in cities if c in city_coords]\n",
    "        if not target_cities:\n",
    "            target_cities = ['Houston', 'Dallas', 'Denver', 'New York', 'Los Angeles', 'Chicago']\n",
    "    frames = []\n",
    "    for c in target_cities:\n",
    "        lat, lon = city_coords[c]\n",
    "        df_c = fetch_city_weather_batched(c, lat, lon, start_date, end_date, timezone=\"UTC\", chunk_days=chunk_days, sleep_sec=sleep_sec)\n",
    "        if not df_c.empty:\n",
    "            frames.append(df_c)\n",
    "    if frames:\n",
    "        out = pd.concat(frames, ignore_index=True)\n",
    "        # rename and standardize\n",
    "        out = out.rename(columns={\n",
    "            'time': 'date',\n",
    "            'temperature_2m_mean': 'temp_mean_c',\n",
    "            'precipitation_sum': 'precip_mm',\n",
    "            'wind_speed_10m_max': 'wind_max_ms'\n",
    "        })\n",
    "        out['date'] = pd.to_datetime(out['date'])\n",
    "        return out\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Example usage - get weather data for the last 30 days\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = \"2007-07-30\"\n",
    "\n",
    "print(\"Example: Getting weather data for major US cities (last 30 days)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b7a3e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data Sample:\n",
      "        date      city  temp_mean_c  precip_mm  wind_max_ms\n",
      "0 2007-07-30  New York         24.3        5.9          7.2\n",
      "1 2007-07-31  New York         25.0        0.1         11.6\n",
      "2 2007-08-01  New York         25.9        0.0          8.6\n",
      "3 2007-08-02  New York         27.6        0.0         12.4\n",
      "4 2007-08-03  New York         27.7        0.3         13.7\n",
      "5 2007-08-04  New York         27.8        0.2         13.4\n",
      "6 2007-08-05  New York         25.0        0.0         15.0\n",
      "7 2007-08-06  New York         24.8        3.3         14.3\n",
      "8 2007-08-07  New York         27.4        0.0         11.5\n",
      "9 2007-08-08  New York         28.4        9.6         18.4\n",
      "Date range: 2007-07-30 to 2025-09-13\n",
      "Cities: 6\n"
     ]
    }
   ],
   "source": [
    "# Demo: Get weather data for specific cities (Open-Meteo)\n",
    "demo_cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'London', 'Tokyo']\n",
    "\n",
    "weather_data = get_weather_data_for_analysis(start_date, end_date, cities=demo_cities)\n",
    "\n",
    "if not weather_data.empty:\n",
    "    print(\"Weather Data Sample:\")\n",
    "    print(weather_data[['date', 'city', 'temp_mean_c', 'precip_mm', 'wind_max_ms']].head(10))\n",
    "    \n",
    "    # Prepare for integration (set index by date)\n",
    "    weather_data = weather_data.set_index('date')\n",
    "    \n",
    "    print(\"Date range:\", weather_data.index.min().strftime('%Y-%m-%d'), \"to\", weather_data.index.max().strftime('%Y-%m-%d'))\n",
    "    print(\"Cities:\", weather_data['city'].nunique())\n",
    "else:\n",
    "    print(\"No weather data available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a08c4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOAA-compatible helper (overrides any previous definition)\n",
    "\n",
    "# def get_weather_data_for_analysis(start_date, end_date, cities=None, usa_only=False):\n",
    "#     \"\"\"Fetch NOAA weather for supported cities over a date range.\"\"\"\n",
    "#     # Use only cities that have mapped stations\n",
    "#     if usa_only or not cities:\n",
    "#         target_cities = ['Houston', 'Dallas', 'Denver', 'New York', 'Los Angeles', 'Chicago']\n",
    "#     else:\n",
    "#         target_cities = [c for c in cities if c in weather_fetcher.weather_stations]\n",
    "#         if not target_cities:\n",
    "#             target_cities = ['Houston', 'Dallas', 'Denver', 'New York', 'Los Angeles', 'Chicago']\n",
    "#     return weather_fetcher.get_multiple_stations_weather(target_cities, start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcbcf708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated weather data with oil data\n",
      "Weather columns added: 9\n",
      "            wti_price  brent_price  temp_mean_c_mean  temp_mean_c_std  \\\n",
      "Date                                                                    \n",
      "2007-07-30  76.830002    75.739998            22.583            4.625   \n",
      "2007-07-31  78.209999    77.050003            23.583            4.367   \n",
      "2007-08-01  76.529999    75.349998            24.467            3.875   \n",
      "2007-08-02  76.860001    75.760002            24.733            4.269   \n",
      "2007-08-03  75.480003    74.750000            24.967            3.988   \n",
      "\n",
      "            temp_mean_c_min  \n",
      "Date                         \n",
      "2007-07-30             14.1  \n",
      "2007-07-31             15.3  \n",
      "2007-08-01             17.0  \n",
      "2007-08-02             16.3  \n",
      "2007-08-03             17.0  \n"
     ]
    }
   ],
   "source": [
    "# Integrate Open-Meteo weather with oil dataframe\n",
    "def integrate_weather_with_oil_data(oil_data, weather_data):\n",
    "    if weather_data.empty:\n",
    "        print(\"No weather data to integrate\")\n",
    "        return oil_data\n",
    "    if not isinstance(oil_data.index, pd.DatetimeIndex):\n",
    "        oil_data.index = pd.to_datetime(oil_data.index)\n",
    "    if not isinstance(weather_data.index, pd.DatetimeIndex):\n",
    "        weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "        weather_data = weather_data.set_index('date')\n",
    "\n",
    "    # Aggregate per day across cities\n",
    "    weather_daily = weather_data.groupby(weather_data.index.date).agg({\n",
    "        'temp_mean_c': ['mean', 'std', 'min', 'max'],\n",
    "        'precip_mm': ['mean', 'sum', 'max'],\n",
    "        'wind_max_ms': ['mean', 'max']\n",
    "    }).round(3)\n",
    "    \n",
    "    weather_daily.columns = ['_'.join(col).strip() for col in weather_daily.columns]\n",
    "    weather_daily.index = pd.to_datetime(weather_daily.index)\n",
    "    combined = oil_data.merge(weather_daily, left_index=True, right_index=True, how='left')\n",
    "    print(\"Integrated weather data with oil data\")\n",
    "    return combined\n",
    "\n",
    "# Example integration with daily contiguous index from oil data\n",
    "if 'weather_data' in locals() and not weather_data.empty and 'raw_data' in locals():\n",
    "    combined_data = integrate_weather_with_oil_data(raw_data, weather_data)\n",
    "    # Reindex to oil dates to ensure adjacency/contiguity\n",
    "    combined_data = combined_data.reindex(raw_data.index)\n",
    "    weather_cols = [c for c in combined_data.columns if any(x in c for x in ['temp_mean_c', 'precip_mm', 'wind_max_ms'])]\n",
    "    print(\"Weather columns added:\", len(weather_cols))\n",
    "    print(combined_data[['wti_price', 'brent_price'] + weather_cols[:3]].head())\n",
    "else:\n",
    "    print(\"Weather data not available for integration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fbb7464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brent_price</th>\n",
       "      <th>wti_price</th>\n",
       "      <th>dxy</th>\n",
       "      <th>10y_yield</th>\n",
       "      <th>vix</th>\n",
       "      <th>eia_inventories</th>\n",
       "      <th>cpi</th>\n",
       "      <th>industrial_production</th>\n",
       "      <th>temp_mean_c_mean</th>\n",
       "      <th>temp_mean_c_std</th>\n",
       "      <th>temp_mean_c_min</th>\n",
       "      <th>temp_mean_c_max</th>\n",
       "      <th>precip_mm_mean</th>\n",
       "      <th>precip_mm_sum</th>\n",
       "      <th>precip_mm_max</th>\n",
       "      <th>wind_max_ms_mean</th>\n",
       "      <th>wind_max_ms_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-07-30</th>\n",
       "      <td>75.739998</td>\n",
       "      <td>76.830002</td>\n",
       "      <td>80.849998</td>\n",
       "      <td>4.804</td>\n",
       "      <td>20.870001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.583</td>\n",
       "      <td>4.625</td>\n",
       "      <td>14.1</td>\n",
       "      <td>27.6</td>\n",
       "      <td>5.300</td>\n",
       "      <td>31.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>12.517</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-07-31</th>\n",
       "      <td>77.050003</td>\n",
       "      <td>78.209999</td>\n",
       "      <td>80.769997</td>\n",
       "      <td>4.771</td>\n",
       "      <td>23.520000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.750811</td>\n",
       "      <td>100.132497</td>\n",
       "      <td>23.583</td>\n",
       "      <td>4.367</td>\n",
       "      <td>15.3</td>\n",
       "      <td>28.2</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.083</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-01</th>\n",
       "      <td>75.349998</td>\n",
       "      <td>76.529999</td>\n",
       "      <td>80.870003</td>\n",
       "      <td>4.759</td>\n",
       "      <td>23.670000</td>\n",
       "      <td>502.074518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.467</td>\n",
       "      <td>3.875</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.567</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.600</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-02</th>\n",
       "      <td>75.760002</td>\n",
       "      <td>76.860001</td>\n",
       "      <td>80.709999</td>\n",
       "      <td>4.753</td>\n",
       "      <td>21.219999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.733</td>\n",
       "      <td>4.269</td>\n",
       "      <td>16.3</td>\n",
       "      <td>27.6</td>\n",
       "      <td>3.250</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.1</td>\n",
       "      <td>14.550</td>\n",
       "      <td>26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-03</th>\n",
       "      <td>74.750000</td>\n",
       "      <td>75.480003</td>\n",
       "      <td>80.180000</td>\n",
       "      <td>4.700</td>\n",
       "      <td>25.160000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.967</td>\n",
       "      <td>3.988</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.050</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-08</th>\n",
       "      <td>66.019997</td>\n",
       "      <td>62.259998</td>\n",
       "      <td>97.449997</td>\n",
       "      <td>4.046</td>\n",
       "      <td>15.110000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.300</td>\n",
       "      <td>5.644</td>\n",
       "      <td>15.1</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.350</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10.700</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-09</th>\n",
       "      <td>66.389999</td>\n",
       "      <td>62.630001</td>\n",
       "      <td>97.790001</td>\n",
       "      <td>4.074</td>\n",
       "      <td>15.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.883</td>\n",
       "      <td>5.017</td>\n",
       "      <td>15.7</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.683</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-10</th>\n",
       "      <td>67.489998</td>\n",
       "      <td>63.669998</td>\n",
       "      <td>97.779999</td>\n",
       "      <td>4.032</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>889.995752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.533</td>\n",
       "      <td>4.855</td>\n",
       "      <td>15.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>2.800</td>\n",
       "      <td>16.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>12.317</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-11</th>\n",
       "      <td>66.370003</td>\n",
       "      <td>62.369999</td>\n",
       "      <td>97.540001</td>\n",
       "      <td>4.011</td>\n",
       "      <td>14.710000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.700</td>\n",
       "      <td>4.663</td>\n",
       "      <td>14.3</td>\n",
       "      <td>27.9</td>\n",
       "      <td>6.750</td>\n",
       "      <td>40.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>13.617</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-12</th>\n",
       "      <td>66.989998</td>\n",
       "      <td>62.689999</td>\n",
       "      <td>97.550003</td>\n",
       "      <td>4.061</td>\n",
       "      <td>14.760000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4566 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            brent_price  wti_price        dxy  10y_yield        vix  \\\n",
       "Date                                                                  \n",
       "2007-07-30    75.739998  76.830002  80.849998      4.804  20.870001   \n",
       "2007-07-31    77.050003  78.209999  80.769997      4.771  23.520000   \n",
       "2007-08-01    75.349998  76.529999  80.870003      4.759  23.670000   \n",
       "2007-08-02    75.760002  76.860001  80.709999      4.753  21.219999   \n",
       "2007-08-03    74.750000  75.480003  80.180000      4.700  25.160000   \n",
       "...                 ...        ...        ...        ...        ...   \n",
       "2025-09-08    66.019997  62.259998  97.449997      4.046  15.110000   \n",
       "2025-09-09    66.389999  62.630001  97.790001      4.074  15.040000   \n",
       "2025-09-10    67.489998  63.669998  97.779999      4.032  15.350000   \n",
       "2025-09-11    66.370003  62.369999  97.540001      4.011  14.710000   \n",
       "2025-09-12    66.989998  62.689999  97.550003      4.061  14.760000   \n",
       "\n",
       "            eia_inventories         cpi  industrial_production  \\\n",
       "Date                                                             \n",
       "2007-07-30              NaN         NaN                    NaN   \n",
       "2007-07-31              NaN  250.750811             100.132497   \n",
       "2007-08-01       502.074518         NaN                    NaN   \n",
       "2007-08-02              NaN         NaN                    NaN   \n",
       "2007-08-03              NaN         NaN                    NaN   \n",
       "...                     ...         ...                    ...   \n",
       "2025-09-08              NaN         NaN                    NaN   \n",
       "2025-09-09              NaN         NaN                    NaN   \n",
       "2025-09-10       889.995752         NaN                    NaN   \n",
       "2025-09-11              NaN         NaN                    NaN   \n",
       "2025-09-12              NaN         NaN                    NaN   \n",
       "\n",
       "            temp_mean_c_mean  temp_mean_c_std  temp_mean_c_min  \\\n",
       "Date                                                             \n",
       "2007-07-30            22.583            4.625             14.1   \n",
       "2007-07-31            23.583            4.367             15.3   \n",
       "2007-08-01            24.467            3.875             17.0   \n",
       "2007-08-02            24.733            4.269             16.3   \n",
       "2007-08-03            24.967            3.988             17.0   \n",
       "...                      ...              ...              ...   \n",
       "2025-09-08            21.300            5.644             15.1   \n",
       "2025-09-09            20.883            5.017             15.7   \n",
       "2025-09-10            21.533            4.855             15.6   \n",
       "2025-09-11            21.700            4.663             14.3   \n",
       "2025-09-12               NaN              NaN              NaN   \n",
       "\n",
       "            temp_mean_c_max  precip_mm_mean  precip_mm_sum  precip_mm_max  \\\n",
       "Date                                                                        \n",
       "2007-07-30             27.6           5.300           31.8           25.8   \n",
       "2007-07-31             28.2           0.017            0.1            0.1   \n",
       "2007-08-01             27.8           0.567            3.4            3.4   \n",
       "2007-08-02             27.6           3.250           19.5           19.1   \n",
       "2007-08-03             27.7           0.333            2.0            1.5   \n",
       "...                     ...             ...            ...            ...   \n",
       "2025-09-08             28.8           0.350            2.1            1.2   \n",
       "2025-09-09             28.6           0.133            0.8            0.5   \n",
       "2025-09-10             28.2           2.800           16.8            7.7   \n",
       "2025-09-11             27.9           6.750           40.5           35.5   \n",
       "2025-09-12              NaN             NaN            0.0            NaN   \n",
       "\n",
       "            wind_max_ms_mean  wind_max_ms_max  \n",
       "Date                                           \n",
       "2007-07-30            12.517             20.4  \n",
       "2007-07-31            11.083             12.9  \n",
       "2007-08-01            12.600             24.9  \n",
       "2007-08-02            14.550             26.4  \n",
       "2007-08-03            18.050             38.5  \n",
       "...                      ...              ...  \n",
       "2025-09-08            10.700             13.4  \n",
       "2025-09-09            10.683             12.8  \n",
       "2025-09-10            12.317             19.4  \n",
       "2025-09-11            13.617             22.8  \n",
       "2025-09-12               NaN              NaN  \n",
       "\n",
       "[4566 rows x 17 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5c77f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['conflict_id', 'dyad_id', 'location_inc', 'side_a', 'side_a_id',\n",
       "       'side_a_2nd', 'side_b', 'side_b_id', 'side_b_2nd', 'incompatibility',\n",
       "       'territory_name', 'year', 'bd_best', 'bd_low', 'bd_high',\n",
       "       'type_of_conflict', 'battle_location', 'gwno_a', 'gwno_a_2nd', 'gwno_b',\n",
       "       'gwno_b_2nd', 'gwno_loc', 'gwno_battle', 'region', 'version'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "death_file_path = 'ucdp-brd-conf-251-csv.zip'\n",
    "#Load UCDP conflict-level data\n",
    "df_deaths = pd.read_csv(death_file_path)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_deaths.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_daily_brd_features(combined_data, death_file_path, \n",
    "                             death_threshold=1000,  # yearly deaths threshold for major war\n",
    "                             rolling_windows=[7,30,90],\n",
    "                             conflict_types=None):\n",
    "    \"\"\"\n",
    "    Merge daily war intensity and flags from UCDP Battle-Related Deaths into a daily oil price dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - combined_data: pd.DataFrame, must have DatetimeIndex\n",
    "    - brd_filepath: str, path to BRD CSV\n",
    "    - death_threshold: int, yearly deaths threshold to flag major war\n",
    "    - rolling_windows: list of ints, window sizes for rolling averages\n",
    "    - conflict_types: list of ints, optional, filter type_of_conflict\n",
    "                      (1=state-based,2=non-state,3=one-sided)\n",
    "    \n",
    "    Returns:\n",
    "    - combined_data merged with daily BRD features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load BRD dataset\n",
    "    df_brd = pd.read_csv(brd_filepath)\n",
    "    \n",
    "    # Optional: filter by type_of_conflict\n",
    "    if conflict_types is not None:\n",
    "        df_brd = df_brd[df_brd['type_of_conflict'].isin(conflict_types)]\n",
    "    \n",
    "    # Aggregate total deaths per year across all dyads\n",
    "    yearly_deaths = df_brd.groupby('year', as_index=False)['bd_best'].sum()\n",
    "    \n",
    "    # Create yearly binary war flag\n",
    "    yearly_deaths['war'] = (yearly_deaths['bd_best'] >= death_threshold).astype(int)\n",
    "    \n",
    "    # Create daily index matching combined_data\n",
    "    daily_index = pd.date_range(start=combined_data.index.min(), end=combined_data.index.max(), freq='D')\n",
    "    daily_war = pd.DataFrame({'date': daily_index})\n",
    "    daily_war['year'] = daily_war['date'].dt.year\n",
    "    \n",
    "    # Merge yearly deaths onto daily index\n",
    "    daily_war = daily_war.merge(yearly_deaths[['year', 'bd_best', 'war']], on='year', how='left')\n",
    "    \n",
    "    # Fill missing years with 0\n",
    "    daily_war['bd_best'] = daily_war['bd_best'].fillna(0).astype(int)\n",
    "    daily_war['war'] = daily_war['war'].fillna(0).astype(int)\n",
    "    daily_war = daily_war.drop(columns='year')\n",
    "    \n",
    "    # Compute rolling averages\n",
    "    for window in rolling_windows:\n",
    "        daily_war[f'deaths_roll_{window}d'] = daily_war['bd_best'].rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    # Set index\n",
    "    daily_war = daily_war.set_index('date')\n",
    "    \n",
    "    # Merge with combined_data\n",
    "    merged = combined_data.join(daily_war, how='left')\n",
    "    \n",
    "    # Fill any remaining NaNs with 0\n",
    "    merged[['bd_best','war'] + [f'deaths_roll_{w}d' for w in rolling_windows]] = \\\n",
    "        merged[['bd_best','war'] + [f'deaths_roll_{w}d' for w in rolling_windows]].fillna(0)\n",
    "    \n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c467bf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "merge_daily_brd_features() missing 1 required positional argument: 'brd_filepath'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m combined_data = \u001b[43mmerge_daily_brd_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: merge_daily_brd_features() missing 1 required positional argument: 'brd_filepath'"
     ]
    }
   ],
   "source": [
    "combined_data = merge_daily_brd_features(combined_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
